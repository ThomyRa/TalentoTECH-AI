{"cells":[{"cell_type":"markdown","id":"73575ae6","metadata":{"papermill":{"duration":0.004925,"end_time":"2023-04-21T13:40:52.185098","exception":false,"start_time":"2023-04-21T13:40:52.180173","status":"completed"},"tags":[],"id":"73575ae6"},"source":["<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fbigdatamagazine.es%2Fwp-content%2Fuploads%2F2023%2F02%2FFOTO-OK-BDM-DIG-DATA-MAGAZINE.jpg&f=1&nofb=1&ipt=4061921fa0da07483f83edb036d31f25545b2cae889c7eeefebd576f6e0fe5f4\" style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n","\n","En este tutorial, aprenderás tres enfoques para **manejar valores faltantes**. Luego compararás la efectividad de estos enfoques utilizando un conjunto de datos del mundo real.\n","\n","# Introducción\n","\n","Existen muchas razones por las que un conjunto de datos puede tener valores faltantes. Por ejemplo:\n","- Una casa de 2 habitaciones no tendrá un valor registrado para el tamaño de una tercera habitación.\n","- Un encuestado puede optar por no revelar su ingreso.\n","\n","La mayoría de las librerías de aprendizaje automático (incluyendo scikit-learn) generan un error si intentas construir un modelo utilizando datos con valores faltantes. Por lo tanto, deberás elegir una de las estrategias que se presentan a continuación."]},{"cell_type":"markdown","id":"76d98a93","metadata":{"papermill":{"duration":0.003361,"end_time":"2023-04-21T13:40:52.192292","exception":false,"start_time":"2023-04-21T13:40:52.188931","status":"completed"},"tags":[],"id":"76d98a93"},"source":["# Tres Enfoques\n","\n","### 1) Una opción simple: eliminar columnas con valores faltantes\n","\n","La opción más simple consiste en eliminar las columnas que contienen valores faltantes.\n","\n","![tut2_approach1](https://storage.googleapis.com/kaggle-media/learn/images/Sax80za.png)\n","\n","A menos que la mayoría de los valores en dichas columnas estén ausentes, con este enfoque el modelo pierde el acceso a una gran cantidad de información (¡potencialmente útil!).  \n","Como ejemplo extremo, imagina un conjunto de datos con 10,000 filas, donde una columna importante solo tiene un único valor faltante. ¡Este enfoque eliminaría la columna por completo!\n","\n","### 2) Una mejor opción: imputación\n","\n","La **imputación** consiste en rellenar los valores faltantes con algún número. Por ejemplo, podemos completar con el valor promedio de cada columna.\n","\n","![tut2_approach2](https://storage.googleapis.com/kaggle-media/learn/images/4BpnlPA.png)\n","\n","El valor imputado no será exactamente correcto en la mayoría de los casos, pero usualmente produce modelos más precisos que si se eliminara la columna completa.\n","\n","### 3) Una extensión de la imputación\n","\n","La imputación es el enfoque estándar y, por lo general, funciona bien. Sin embargo, los valores imputados pueden estar sistemáticamente por encima o por debajo de sus valores reales (los cuales no se recolectaron). O bien, las filas con valores faltantes pueden ser únicas en otros aspectos. En estos casos, el modelo puede generar mejores predicciones si tiene en cuenta qué valores estaban originalmente ausentes.\n","\n","![tut3_approach3](https://storage.googleapis.com/kaggle-media/learn/images/UWOyg4a.png)\n","\n","En este enfoque, imputamos los valores faltantes como antes. Además, para cada columna que contenía valores faltantes en el conjunto de datos original, añadimos una nueva columna que indica la ubicación de las entradas imputadas.\n","\n","En algunos casos, esto mejora significativamente los resultados. En otros casos, no ayuda en absoluto.\n","\n","# Ejemplo\n","\n","En el siguiente ejemplo trabajaremos con el [conjunto de datos de viviendas de Melbourne](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/home). Nuestro modelo utilizará información como el número de habitaciones y el tamaño del terreno para predecir el precio de la vivienda.\n","\n","No nos centraremos en el paso de carga de datos. En su lugar, imaginaremos que ya tienes los datos de entrenamiento y validación disponibles en las variables `X_train`, `X_valid`, `y_train` y `y_valid`.\n"]},{"cell_type":"code","execution_count":1,"id":"aa8e5f23","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-04-21T13:40:52.202085Z","iopub.status.busy":"2023-04-21T13:40:52.201222Z","iopub.status.idle":"2023-04-21T13:40:53.588600Z","shell.execute_reply":"2023-04-21T13:40:53.587445Z"},"papermill":{"duration":1.395479,"end_time":"2023-04-21T13:40:53.591425","exception":false,"start_time":"2023-04-21T13:40:52.195946","status":"completed"},"tags":[],"id":"aa8e5f23","executionInfo":{"status":"ok","timestamp":1751731475144,"user_tz":300,"elapsed":5257,"user":{"displayName":"Thomas","userId":"16408437999216828683"}}},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Cargar los datos\n","data = pd.read_csv('/content/melb_data.csv')\n","\n","# Seleccionar la variable objetivo\n","y = data.Price\n","\n","# Para simplificar, utilizaremos únicamente predictores numéricos\n","melb_predictors = data.drop(['Price'], axis=1)\n","X = melb_predictors.select_dtypes(exclude=['object'])\n","\n","# Dividir los datos en subconjuntos de entrenamiento y validación\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n","                                                      random_state=0)"]},{"cell_type":"markdown","id":"5d43df63","metadata":{"papermill":{"duration":0.003595,"end_time":"2023-04-21T13:40:53.599519","exception":false,"start_time":"2023-04-21T13:40:53.595924","status":"completed"},"tags":[],"id":"5d43df63"},"source":["### Definimos la función para medir la calidad de cada enfoque\n","\n","Definimos una función llamada `score_dataset()` para comparar los diferentes enfoques para tratar los valores faltantes. Esta función reporta el [error absoluto medio (MAE)](https://es.wikipedia.org/wiki/Error_absoluto_medio) utilizando un modelo de bosque aleatorio."]},{"cell_type":"code","execution_count":3,"id":"75b71fcd","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-04-21T13:40:53.608718Z","iopub.status.busy":"2023-04-21T13:40:53.608282Z","iopub.status.idle":"2023-04-21T13:40:54.012025Z","shell.execute_reply":"2023-04-21T13:40:54.010658Z"},"papermill":{"duration":0.411656,"end_time":"2023-04-21T13:40:54.014914","exception":false,"start_time":"2023-04-21T13:40:53.603258","status":"completed"},"tags":[],"id":"75b71fcd","executionInfo":{"status":"ok","timestamp":1751731732883,"user_tz":300,"elapsed":953,"user":{"displayName":"Thomas","userId":"16408437999216828683"}}},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Función para comparar diferentes enfoques\n","def score_dataset(X_train, X_valid, y_train, y_valid):\n","    model = RandomForestRegressor(n_estimators=10, random_state=0)\n","    model.fit(X_train, y_train)\n","    preds = model.predict(X_valid)\n","    return mean_absolute_error(y_valid, preds)"]},{"cell_type":"markdown","id":"0061d804","metadata":{"papermill":{"duration":0.003579,"end_time":"2023-04-21T13:40:54.022394","exception":false,"start_time":"2023-04-21T13:40:54.018815","status":"completed"},"tags":[],"id":"0061d804"},"source":["### Puntaje del Enfoque 1 (Eliminar columnas con valores faltantes)\n","\n","Como estamos trabajando con conjuntos de entrenamiento y validación, debemos asegurarnos de eliminar las mismas columnas en ambos `DataFrames`."]},{"cell_type":"code","execution_count":4,"id":"f1ef567d","metadata":{"execution":{"iopub.execute_input":"2023-04-21T13:40:54.031964Z","iopub.status.busy":"2023-04-21T13:40:54.031522Z","iopub.status.idle":"2023-04-21T13:40:54.542657Z","shell.execute_reply":"2023-04-21T13:40:54.541264Z"},"papermill":{"duration":0.519409,"end_time":"2023-04-21T13:40:54.545608","exception":false,"start_time":"2023-04-21T13:40:54.026199","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"f1ef567d","executionInfo":{"status":"ok","timestamp":1751731737400,"user_tz":300,"elapsed":839,"user":{"displayName":"Thomas","userId":"16408437999216828683"}},"outputId":"5172c342-e7f5-4991-8d11-381839fcb269"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE del Enfoque 1 (Eliminar columnas con valores faltantes):\n","183550.22137772635\n"]}],"source":["# Obtener los nombres de las columnas con valores faltantes\n","cols_with_missing = [col for col in X_train.columns\n","                     if X_train[col].isnull().any()]\n","\n","# Eliminar las columnas con valores faltantes en los datos de entrenamiento y validación\n","reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n","reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n","\n","print(\"MAE del Enfoque 1 (Eliminar columnas con valores faltantes):\")\n","print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n"]},{"cell_type":"markdown","id":"4827843b","metadata":{"papermill":{"duration":0.003713,"end_time":"2023-04-21T13:40:54.553650","exception":false,"start_time":"2023-04-21T13:40:54.549937","status":"completed"},"tags":[],"id":"4827843b"},"source":["### Puntaje del Enfoque 2 (Imputación)\n","\n","A continuación, utilizamos [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) para reemplazar los valores faltantes con el valor medio (promedio) de cada columna.\n","\n","Aunque es un método simple, rellenar con el valor medio generalmente ofrece buenos resultados (aunque esto puede variar según el conjunto de datos).  \n","Si bien los estadísticos han experimentado con métodos más complejos para determinar los valores imputados (como la **imputación por regresión**, por ejemplo), estas estrategias sofisticadas normalmente no aportan beneficios adicionales cuando los resultados se integran en modelos avanzados de aprendizaje automático.\n"]},{"cell_type":"code","execution_count":5,"id":"09687042","metadata":{"execution":{"iopub.execute_input":"2023-04-21T13:40:54.564084Z","iopub.status.busy":"2023-04-21T13:40:54.563095Z","iopub.status.idle":"2023-04-21T13:40:55.216772Z","shell.execute_reply":"2023-04-21T13:40:55.215374Z"},"papermill":{"duration":0.661708,"end_time":"2023-04-21T13:40:55.219381","exception":false,"start_time":"2023-04-21T13:40:54.557673","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"09687042","executionInfo":{"status":"ok","timestamp":1751731865085,"user_tz":300,"elapsed":1667,"user":{"displayName":"Thomas","userId":"16408437999216828683"}},"outputId":"1ed5e07c-c13e-48d7-aedb-f43ac9f85dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE del Enfoque 2 (Imputación):\n","178166.46269899711\n"]}],"source":["from sklearn.impute import SimpleImputer\n","\n","# Imputación\n","my_imputer = SimpleImputer()\n","imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n","imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n","\n","# La imputación eliminó los nombres de las columnas; los restauramos\n","imputed_X_train.columns = X_train.columns\n","imputed_X_valid.columns = X_valid.columns\n","\n","print(\"MAE del Enfoque 2 (Imputación):\")\n","print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n"]},{"cell_type":"markdown","id":"505cef52","metadata":{"papermill":{"duration":0.00408,"end_time":"2023-04-21T13:40:55.227608","exception":false,"start_time":"2023-04-21T13:40:55.223528","status":"completed"},"tags":[],"id":"505cef52"},"source":["Observamos que el **Enfoque 2** tiene un MAE menor que el **Enfoque 1**, por lo tanto, el **Enfoque 2** tuvo un mejor desempeño en este conjunto de datos.\n","\n","### Puntaje del Enfoque 3 (Una extensión de la imputación)\n","\n","A continuación, imputamos los valores faltantes, pero además registramos qué valores fueron imputados."]},{"cell_type":"code","execution_count":6,"id":"c6c621f7","metadata":{"execution":{"iopub.execute_input":"2023-04-21T13:40:55.239224Z","iopub.status.busy":"2023-04-21T13:40:55.238079Z","iopub.status.idle":"2023-04-21T13:40:55.964457Z","shell.execute_reply":"2023-04-21T13:40:55.962944Z"},"papermill":{"duration":0.735324,"end_time":"2023-04-21T13:40:55.967310","exception":false,"start_time":"2023-04-21T13:40:55.231986","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"c6c621f7","executionInfo":{"status":"ok","timestamp":1751732748091,"user_tz":300,"elapsed":4101,"user":{"displayName":"Thomas","userId":"16408437999216828683"}},"outputId":"02cdbf59-037a-4793-f2a3-5f5610d9466e"},"outputs":[{"output_type":"stream","name":"stdout","text":["MAE del Enfoque 3 (Una extensión de la imputación):\n","178927.503183954\n"]}],"source":["# Hacer una copia para evitar modificar los datos originales (durante la imputación)\n","X_train_plus = X_train.copy()\n","X_valid_plus = X_valid.copy()\n","\n","# Crear nuevas columnas que indiquen qué valores serán imputados\n","for col in cols_with_missing:\n","    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n","    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n","\n","# Imputación\n","my_imputer = SimpleImputer()\n","imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n","imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n","\n","# La imputación eliminó los nombres de las columnas; los restauramos\n","imputed_X_train_plus.columns = X_train_plus.columns\n","imputed_X_valid_plus.columns = X_valid_plus.columns\n","\n","print(\"MAE del Enfoque 3 (Una extensión de la imputación):\")\n","print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n"]},{"cell_type":"markdown","id":"2aaff5c0","metadata":{"papermill":{"duration":0.004371,"end_time":"2023-04-21T13:40:55.976319","exception":false,"start_time":"2023-04-21T13:40:55.971948","status":"completed"},"tags":[],"id":"2aaff5c0"},"source":["Como podemos ver, el **Enfoque 3** tuvo un rendimiento ligeramente inferior al del **Enfoque 2**.\n","\n","### Entonces, ¿por qué la imputación tuvo mejor desempeño que eliminar las columnas?\n","\n","El conjunto de datos de entrenamiento tiene 10,864 filas y 12 columnas, de las cuales tres contienen valores faltantes.  \n","En cada una de estas columnas, menos de la mitad de las entradas están ausentes. Por lo tanto, eliminar estas columnas implica descartar una gran cantidad de información útil, lo que explica por qué la imputación ofrece un mejor rendimiento."]},{"cell_type":"code","execution_count":7,"id":"c46bd5d6","metadata":{"execution":{"iopub.execute_input":"2023-04-21T13:40:55.988155Z","iopub.status.busy":"2023-04-21T13:40:55.987016Z","iopub.status.idle":"2023-04-21T13:40:55.998281Z","shell.execute_reply":"2023-04-21T13:40:55.997136Z"},"papermill":{"duration":0.020267,"end_time":"2023-04-21T13:40:56.000823","exception":false,"start_time":"2023-04-21T13:40:55.980556","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"c46bd5d6","executionInfo":{"status":"ok","timestamp":1751733025674,"user_tz":300,"elapsed":15,"user":{"displayName":"Thomas","userId":"16408437999216828683"}},"outputId":"0e4a8db7-4e42-4c16-d893-f6a428422116"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10864, 12)\n","Car               49\n","BuildingArea    5156\n","YearBuilt       4307\n","dtype: int64\n"]}],"source":["# Dimensión del conjunto de entrenamiento (número de filas, número de columnas)\n","print(X_train.shape)\n","\n","# Número de valores faltantes en cada columna del conjunto de entrenamiento\n","missing_val_count_by_column = (X_train.isnull().sum())\n","print(missing_val_count_by_column[missing_val_count_by_column > 0])\n"]},{"cell_type":"markdown","id":"468ddf78","metadata":{"papermill":{"duration":0.00485,"end_time":"2023-04-21T13:40:56.010418","exception":false,"start_time":"2023-04-21T13:40:56.005568","status":"completed"},"tags":[],"id":"468ddf78"},"source":["# Conclusión\n","\n","Como es habitual, imputar los valores faltantes (en el **Enfoque 2** y el **Enfoque 3**) produjo mejores resultados en comparación con simplemente eliminar las columnas con valores faltantes (como en el **Enfoque 1**)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":15.891205,"end_time":"2023-04-21T13:40:56.746001","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-21T13:40:40.854796","version":"2.4.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}