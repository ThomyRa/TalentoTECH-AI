{"cells":[{"cell_type":"markdown","id":"8bfc0a5c","metadata":{"papermill":{"duration":0.003615,"end_time":"2023-04-21T13:39:13.195933","exception":false,"start_time":"2023-04-21T13:39:13.192318","status":"completed"},"tags":[],"id":"8bfc0a5c"},"source":["<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fbigdatamagazine.es%2Fwp-content%2Fuploads%2F2023%2F02%2FFOTO-OK-BDM-DIG-DATA-MAGAZINE.jpg&f=1&nofb=1&ipt=4061921fa0da07483f83edb036d31f25545b2cae889c7eeefebd576f6e0fe5f4\" style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n","\n","\n","Al final de este paso, comprenderás los conceptos de **subajuste** (*underfitting*) y **sobreajuste** (*overfitting*), y serás capaz de aplicar estas ideas para hacer que tus modelos sean más precisos.\n","\n","# Experimentar con Diferentes Modelos\n","\n","Ahora que tienes una forma confiable de medir la precisión del modelo, puedes experimentar con modelos alternativos y ver cuál ofrece las mejores predicciones. Pero, ¿qué alternativas tienes?\n","\n","Puedes consultar en la [documentación de scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) que el modelo de árbol de decisión tiene muchas opciones (más de las que vas a querer o necesitar durante un buen tiempo). Las opciones más importantes determinan la **profundidad del árbol**. Recuerda que la profundidad del árbol mide cuántas divisiones realiza antes de llegar a una predicción. Este es un árbol relativamente poco profundo:\n","\n","![Árbol de profundidad 2](https://storage.googleapis.com/kaggle-media/learn/images/R3ywQsR.png)\n","\n","En la práctica, no es raro que un árbol tenga 10 divisiones entre el nivel superior (todas las casas) y una hoja. A medida que el árbol se hace más profundo, el conjunto de datos se divide en hojas con menos viviendas. Si un árbol tiene solo 1 división, separa los datos en 2 grupos. Si cada grupo se divide de nuevo, obtendríamos 4 grupos de casas. Si volvemos a dividir cada uno de esos, se crean 8 grupos. Si continuamos duplicando el número de grupos agregando más divisiones en cada nivel, tendremos \\\\(2^{10}\\\\) grupos de viviendas al llegar al nivel 10. Eso son 1024 hojas.\n","\n","Cuando dividimos las viviendas en muchas hojas, también hay menos casas por hoja. Las hojas con muy pocas casas generarán predicciones muy cercanas a los valores reales de esas viviendas, pero podrían ser predicciones muy poco confiables para nuevos datos (porque se basan en muy pocas observaciones).\n","\n","Este fenómeno se llama **sobreajuste** (*overfitting*), donde un modelo se ajusta casi perfectamente a los datos de entrenamiento, pero tiene un rendimiento deficiente en los datos de validación y en datos nuevos. Por otro lado, si hacemos nuestro árbol muy poco profundo, no divide las viviendas en grupos realmente distintos.\n","\n","En un caso extremo, si un árbol divide las viviendas en solo 2 o 4 grupos, cada grupo aún contendría una gran variedad de viviendas. Las predicciones resultantes podrían estar muy alejadas del valor real para la mayoría de las casas, incluso en los datos de entrenamiento (y también serían malas en los datos de validación por la misma razón). Cuando un modelo no logra capturar distinciones y patrones importantes en los datos, y por tanto tiene un mal desempeño incluso en entrenamiento, a eso se le llama **subajuste** (*underfitting*).\n","\n","Dado que nos importa la precisión sobre datos nuevos —que estimamos usando los datos de validación— queremos encontrar el punto ideal entre subajuste y sobreajuste. Visualmente, queremos llegar al punto más bajo de la curva (roja) de validación en la siguiente figura:\n","\n","![subajuste_sobreajuste](https://storage.googleapis.com/kaggle-media/learn/images/AXSEOfI.png)\n","\n","# Ejemplo\n","\n","Existen varias alternativas para controlar la profundidad del árbol, y muchas permiten que algunas ramas del árbol tengan mayor profundidad que otras. Pero el argumento *max_leaf_nodes* proporciona una forma muy razonable de controlar el sobreajuste frente al subajuste. Cuantas más hojas permitamos que el modelo cree, más nos desplazamos desde la zona de subajuste hacia la zona de sobreajuste en la gráfica anterior.\n","\n","Podemos utilizar una función auxiliar para comparar los valores de MAE obtenidos con diferentes configuraciones del parámetro *max_leaf_nodes*:\n","\n"]},{"cell_type":"code","execution_count":3,"id":"d623abfe","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-04-21T13:39:13.204256Z","iopub.status.busy":"2023-04-21T13:39:13.203370Z","iopub.status.idle":"2023-04-21T13:39:14.606284Z","shell.execute_reply":"2023-04-21T13:39:14.604881Z"},"papermill":{"duration":1.41049,"end_time":"2023-04-21T13:39:14.609334","exception":false,"start_time":"2023-04-21T13:39:13.198844","status":"completed"},"tags":[],"id":"d623abfe","executionInfo":{"status":"ok","timestamp":1751727541052,"user_tz":300,"elapsed":463,"user":{"displayName":"Thomas","userId":"16408437999216828683"}}},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.tree import DecisionTreeRegressor\n","\n","def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n","    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n","    model.fit(train_X, train_y)\n","    preds_val = model.predict(val_X)\n","    mae = mean_absolute_error(val_y, preds_val)\n","    return(mae)"]},{"cell_type":"markdown","id":"15a4e36f","metadata":{"papermill":{"duration":0.002283,"end_time":"2023-04-21T13:39:14.614422","exception":false,"start_time":"2023-04-21T13:39:14.612139","status":"completed"},"tags":[],"id":"15a4e36f"},"source":["Los datos se han cargado en **train_X**, **val_X**, **train_y** y **val_y** utilizando el código que ya has visto (y que ya has escrito)."]},{"cell_type":"code","execution_count":1,"id":"1c7e9118","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-04-21T13:39:14.621596Z","iopub.status.busy":"2023-04-21T13:39:14.621196Z","iopub.status.idle":"2023-04-21T13:39:14.757622Z","shell.execute_reply":"2023-04-21T13:39:14.756434Z"},"papermill":{"duration":0.143603,"end_time":"2023-04-21T13:39:14.760597","exception":false,"start_time":"2023-04-21T13:39:14.616994","status":"completed"},"tags":[],"id":"1c7e9118","executionInfo":{"status":"ok","timestamp":1751727467095,"user_tz":300,"elapsed":1666,"user":{"displayName":"Thomas","userId":"16408437999216828683"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Cargar los datos\n","melbourne_file_path = '/content//melb_data.csv'\n","melbourne_data = pd.read_csv(melbourne_file_path)\n","\n","# Filtrar las filas con valores faltantes\n","filtered_melbourne_data = melbourne_data.dropna(axis=0)\n","\n","# Seleccionar la variable objetivo (target) y las características (features)\n","y = filtered_melbourne_data.Price\n","melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea',\n","                      'YearBuilt', 'Lattitude', 'Longtitude']\n","X = filtered_melbourne_data[melbourne_features]\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Dividir los datos en conjuntos de entrenamiento y validación, tanto para características como para la variable objetivo\n","train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)"]},{"cell_type":"markdown","id":"43eb9643","metadata":{"papermill":{"duration":0.002466,"end_time":"2023-04-21T13:39:14.765840","exception":false,"start_time":"2023-04-21T13:39:14.763374","status":"completed"},"tags":[],"id":"43eb9643"},"source":["Podemos utilizar un ciclo `for` para comparar la precisión de los modelos construidos con diferentes valores para *max_leaf_nodes*."]},{"cell_type":"code","execution_count":4,"id":"7a75b55d","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-04-21T13:39:14.773179Z","iopub.status.busy":"2023-04-21T13:39:14.772697Z","iopub.status.idle":"2023-04-21T13:39:14.870009Z","shell.execute_reply":"2023-04-21T13:39:14.868719Z"},"papermill":{"duration":0.104742,"end_time":"2023-04-21T13:39:14.873136","exception":false,"start_time":"2023-04-21T13:39:14.768394","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"7a75b55d","executionInfo":{"status":"ok","timestamp":1751727543776,"user_tz":300,"elapsed":112,"user":{"displayName":"Thomas","userId":"16408437999216828683"}},"outputId":"057d5660-c711-4edb-9da2-b603b75eeb96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Máximo número de hojas: 5  \t\t Error Absoluto Medio:  347380\n","Máximo número de hojas: 50  \t\t Error Absoluto Medio:  258171\n","Máximo número de hojas: 500  \t\t Error Absoluto Medio:  243495\n","Máximo número de hojas: 5000  \t\t Error Absoluto Medio:  255575\n"]}],"source":["# Comparar el MAE con diferentes valores de max_leaf_nodes\n","for max_leaf_nodes in [5, 50, 500, 5000]:\n","    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n","    print(\"Máximo número de hojas: %d  \\t\\t Error Absoluto Medio:  %d\" % (max_leaf_nodes, my_mae))"]},{"cell_type":"markdown","id":"0b89b025","metadata":{"papermill":{"duration":0.002437,"end_time":"2023-04-21T13:39:14.878456","exception":false,"start_time":"2023-04-21T13:39:14.876019","status":"completed"},"tags":[],"id":"0b89b025"},"source":["De las opciones listadas, 500 es el número óptimo de hojas.\n","\n","---\n","\n","# Conclusión\n","\n","Esto es lo que debes tener en cuenta: los modelos pueden verse afectados por:\n","\n","- **Sobreajuste (overfitting):** cuando capturan patrones espurios que no se repetirán en el futuro, lo que lleva a predicciones menos precisas.\n","- **Subajuste (underfitting):** cuando no logran capturar patrones relevantes, también resultando en predicciones poco precisas.\n","\n","Utilizamos datos de **validación**, que no se usan en el entrenamiento del modelo, para medir la precisión de un modelo candidato. Esto nos permite probar muchos modelos y conservar el que tenga el mejor desempeño.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":15.724019,"end_time":"2023-04-21T13:39:18.418124","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-21T13:39:02.694105","version":"2.4.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}